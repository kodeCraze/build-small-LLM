{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "E0JPhJeLZqLY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1991ff1-6bb9-42de-a343-a91dacd77e1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'h': 0, 'e': 1, 'l': 2, 'o': 3}\n",
            "[0, 1, 2, 2, 3]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Our training data: \"hello\"\n",
        "text = \"hello\"\n",
        "\n",
        "# Create a vocabulary (unique characters)\n",
        "chars = ['h', 'e', 'l', 'o']\n",
        "vocab_size = len(chars)  # 4 characters\n",
        "\n",
        "# Create a dictionary to map characters to numbers\n",
        "char_to_idx = {char: i for i, char in enumerate(chars)}\n",
        "print(char_to_idx)  # {'h':0, 'e':1, 'l':2, 'o':3}\n",
        "\n",
        "# Convert the entire \"hello\" to numbers\n",
        "encoded_text = [char_to_idx[c] for c in text]\n",
        "print(encoded_text)  # [0, 1, 2, 2, 3]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input sequence length (context window)\n",
        "seq_length = 3  # Model sees 3 characters to predict the 4th\n",
        "\n",
        "# Create input sequences (X) and target characters (y)\n",
        "X = []  # Inputs (lists of 3 numbers)\n",
        "y = []  # Targets (single number)\n",
        "\n",
        "for i in range(len(encoded_text) - seq_length):\n",
        "    X.append(encoded_text[i:i+seq_length])  # First 3 chars\n",
        "    y.append(encoded_text[i+seq_length])    # 4th char\n",
        "\n",
        "# Convert to PyTorch tensors (arrays)\n",
        "X = torch.tensor(X)\n",
        "y = torch.tensor(y)\n",
        "\n",
        "print(\"Inputs (X):\\n\", X)\n",
        "print(\"Targets (y):\\n\", y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Il7PV9S9aHpP",
        "outputId": "8ad8c4b1-b9e9-4c12-cd49-90bdc0aa5a99"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs (X):\n",
            " tensor([[0, 1, 2],\n",
            "        [1, 2, 2]])\n",
            "Targets (y):\n",
            " tensor([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TinyModel(torch.nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.embedding = torch.nn.Embedding(vocab_size, 8)  # 8-dimensional embeddings\n",
        "        self.rnn = torch.nn.RNN(8, 16, batch_first=True)    # 16 hidden units\n",
        "        self.fc = torch.nn.Linear(16, vocab_size)           # Final prediction layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Step 1: Embed the input (turn numbers into vectors)\n",
        "        x = self.embedding(x)  # Shape: (batch_size, seq_length, 8)\n",
        "\n",
        "        # Step 2: Pass through RNN\n",
        "        out, _ = self.rnn(x)   # Shape: (batch_size, seq_length, 16)\n",
        "\n",
        "        # Step 3: Take the last output of the RNN\n",
        "        out = out[:, -1, :]    # Shape: (batch_size, 16)\n",
        "\n",
        "        # Step 4: Predict the next character\n",
        "        logits = self.fc(out)  # Shape: (batch_size, vocab_size)\n",
        "        return logits\n",
        "\n",
        "model = TinyModel(vocab_size)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UN0Mek0taIYG",
        "outputId": "0bcbe2f4-c4a3-40fe-8270-20bb92da1c91"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TinyModel(\n",
            "  (embedding): Embedding(4, 8)\n",
            "  (rnn): RNN(8, 16, batch_first=True)\n",
            "  (fc): Linear(in_features=16, out_features=4, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function: Measures how wrong the model is\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer: Adjusts the model's weights to reduce loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
        "\n",
        "# Training loop (teach the model 100 times)\n",
        "for epoch in range(100):\n",
        "    # Forward pass\n",
        "    outputs = model(X)  # Model makes predictions\n",
        "    loss = criterion(outputs, y)  # Compare predictions to targets\n",
        "\n",
        "    # Backward pass (learn from mistakes)\n",
        "    optimizer.zero_grad()  # Reset gradients\n",
        "    loss.backward()        # Compute gradients\n",
        "    optimizer.step()       # Update weights\n",
        "\n",
        "    # Print progress\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYSe75UKaP1G",
        "outputId": "bcd5db60-fd6c-420e-e173-ff509ec671de"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 1.2616\n",
            "Epoch 10, Loss: 0.0011\n",
            "Epoch 20, Loss: 0.0001\n",
            "Epoch 30, Loss: 0.0000\n",
            "Epoch 40, Loss: 0.0000\n",
            "Epoch 50, Loss: 0.0000\n",
            "Epoch 60, Loss: 0.0000\n",
            "Epoch 70, Loss: 0.0000\n",
            "Epoch 80, Loss: 0.0000\n",
            "Epoch 90, Loss: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_char(model, start_str):\n",
        "    model.eval()  # Switch to evaluation mode\n",
        "    chars = [char_to_idx[c] for c in start_str]  # Convert \"hel\" to [0,1,2]\n",
        "\n",
        "    # Predict next character\n",
        "    x = torch.tensor(chars).unsqueeze(0)  # Add batch dimension\n",
        "    pred = model(x)                       # Shape: (1, 4)\n",
        "    next_char_idx = torch.argmax(pred).item()  # Get most likely index\n",
        "\n",
        "    # Convert back to character\n",
        "    next_char = idx_to_char[next_char_idx]\n",
        "    return next_char\n",
        "\n",
        "# Test the model\n",
        "start_str = \"hel\"\n",
        "predicted_char = predict_next_char(model, start_str)\n",
        "print(f\"After '{start_str}', the model predicts: '{predicted_char}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grzbqlUHaRnH",
        "outputId": "07925656-7ba2-47be-8923-32c5ba028003"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After 'hel', the model predicts: 'e'\n"
          ]
        }
      ]
    }
  ]
}